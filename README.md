# Assignment 2

保护隐私，隐藏身份信息

## 运行方法

### 完整系统运行流程

#### 1. 数据预处理阶段
**PDF转文本处理**
```bash
python3 .aux/数据库-哈利波特/pdf_convert_to_txt.py
```
- 自动处理PDF资料，提取文本内容
- 建立原始文本数据库

#### 2. 语料清洗阶段
**LLM支持的自动语料清洗**
```bash
python3 .aux/数据库-哈利波特/txt_batches/去掉多余空行/Corpus_Typo.py
```
- 实现格式清洗和规范化
- 使用LLM进行智能语料处理

#### 3. 向量化处理阶段
**文本资料库转FAISS语义向量**
```bash
python3 .aux/数据库-哈利波特/embedding/processor.py
```
- 自动将文本资料库转换为FAISS语义向量
- 建立语料库的查找索引
- 只需运行一次即可建立完整的语义搜索系统

#### 4. 主程序运行
**智能对话系统**
```bash
python3 code/LLM_improved.py
```
- 调用已建立的语义搜索功能
- 自动检测哈利波特相关问题
- 智能调用搜索工具并解释利用的信息

### 环境配置
1. **FAISS配置**：FAISS向量数据库的相关配置在`config.yaml`文件中设置
2. **网络要求**：由于FAISS使用了需要翻墙的模型，在生成向量索引和查询时都需要翻墙环境
3. 安装依赖: `pip install openai python-dotenv`
4. 在项目目录下的`.env`文件添加自己的API密钥:
   ```
   API_KEY=your_api_key_here
   ```
5. 按照上述顺序运行各阶段程序

## 主要功能
- **智能工具调用系统**：自动检测哈利波特相关问题并调用搜索工具
- **改进的反复核验机制**：逐步查询更多文本直到获得足够信息，兼顾了信息完整可信和运行速度、内存消耗的平衡
- **工具利用解释**：在调用工具后自动要求agent解释如何利用工具信息
- **内存优化**：自动清理工具返回内容以节省存储空间
- **高度可复用框架**：整个系统流程可以套用在任意领域，只需替换相应的语料库和工具配置

## 主要结果

### 1. 智能哈利波特工具集成
- **自动问题分类**：使用LLM判断问题是否与哈利波特相关
- **关键词提取**：让LLM思考需要哪些关键词来搜索原文
- **渐进式查询**：从1个文本开始，逐步增加到最多6个文本
- **信息充足性验证**：每次查询后验证信息是否足够回答问题

### 2. 工具利用解释功能
- **在每个调用了哈利波特搜索工具的轮次后面添加一段对话**
- 自动添加用户问题："请解释你刚才的回答是如何利用哈利波特搜索工具提供的信息的？具体说明你参考了哪些原文片段，以及这些信息如何帮助你回答问题。"
- 显示完整的对话流程，包括用户提问和agent解释
- 将解释对话添加到消息历史中，保持对话的连续性

### 3. 改进工具调用处理
- 当工具被调用时，将工具调用和响应添加到消息历史中
- 重新调用API获取最终回复
- 在工具返回信息后，显示新的"Agent:"提示，开启新的一轮回答
- **修复了agent在回答时重复输出工具返回信息的问题**

### 4. 内存优化和消息清理
- 在每轮对话结束后，遍历消息历史
- 识别所有`role: 'tool'`的消息
- 将这些消息的`content`字段替换为"已清除内存"
- 保留工具消息的结构和`tool_call_id`，确保符合OpenAI API标准
- 大幅减少消息历史占用的存储空间，同时保持工具调用的上下文完整性

### 5. 功能取消说明（抱歉）
由于bug太多，不得不取消以下功能：
- **取消重试机制**：移除了MAX_RETRIES和RETRY_DELAY参数，删除了所有重试循环和重试逻辑
- **取消流式传输机制**：将所有API调用的`stream=True`改为`stream=False`，移除了流式传输相关的代码

### 6. 程序稳定性说明
现在的程序还是可能有不少bug的，比如无法正确处理空输出，此时可能需要重新运行整个程序。
一个比较正常运行的轮次可以参考result文件夹中的截图；这个对话最后也因为bug没有正确的存储下对话历史。

## 系统优势与改进潜力

### 1. **多轮核验机制的创新设计**
- **信息完整性与效率平衡**：渐进式查询机制在保证信息完整可信的同时，兼顾了运行速度和内存消耗
- **智能终止条件**：通过信息充足性验证，避免不必要的查询轮次，提升系统效率
- **资源优化**：从少量文本开始逐步增加，有效控制API调用次数和计算资源消耗

### 2. **高度可复用的系统框架**
- **模块化设计**：整个系统流程可以套用在任意领域，只需替换相应的语料库和工具配置
- **标准化接口**：符合OpenAI API标准，便于集成和扩展
- **灵活的配置机制**：通过配置文件支持不同应用场景的快速适配

### 3. **当前局限性与改进方向**
- **FAISS文本划分优化**：当前效果不够理想的主要原因是FAISS的文本划分还不够合理
- **搜索精度提升**：搜索方式不够精确，目前主要依赖关键词语义的FAISS比对
- **框架潜力**：相信这种实现框架能够通过更仔细地实现来达到更好的效果，包括：
  - 更精细的文本切分策略
  - 更准确的语义匹配算法
  - 更智能的查询优化机制

## 基于Cline的编程辅助过程

### 1. **代码重构与规范化**
- 初始版本`LLM.py`由本人独立搭建完成
- 在Cline的辅助下对整个代码结构进行了系统性重构
- 优化了代码架构，提升了可维护性和扩展性

### 2. **功能优化与标准符合性改进**
- **取消重试机制**：在Cline指导下逐步移除重试循环、空响应处理机制及相关参数配置
- **取消流式传输**：将API调用从流式传输改为完整响应模式
- **消息结构标准化**：调整message信息格式，确保完全符合OpenAI API标准规范

### 3. **内存优化与稳定性权衡**
- **消息清理机制**：在Cline协助下实现每轮对话后的message列表清洗功能
- **技术权衡分析**：内存优化虽然解决了API阅读时间过长导致的报错问题，但引入了稳定性挑战
- **语料筛选优化**：通过tool中增加语料筛选轮次，部分缓解了API超时问题
- **稳定性代价**：各项优化措施在提升性能的同时，不可避免地降低了系统的整体稳定性
